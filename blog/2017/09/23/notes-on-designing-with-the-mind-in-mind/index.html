<!DOCTYPE html><html lang="en"><meta charset="utf-8" /><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0"><title>Notes on 'Designing with the Mind in Mind'</title><meta name="author" content="Jamie Brandon" /><link rel="alternate" type="application/rss+xml" title="Scattered Thoughts - " href="/feed.xml" /><style> @import url("https://fonts.googleapis.com/css?family=Fira+Code:400,700|Fira+Sans:400,400i,700,700i&display=swap");progress,sub,sup{vertical-align:baseline}button,hr,input{overflow:visible}html{font-family:sans-serif;line-height:1.15;-ms-text-size-adjust:100%;-webkit-text-size-adjust:100%}body{margin:0}figcaption,menu,article,aside,details,figure,footer,header,main,nav,section,summary{display:block}audio,canvas,progress,video{display:inline-block}audio:not([controls]){display:none;height:0}[hidden],template{display:none}a{background-color:transparent;-webkit-text-decoration-skip:objects}a:active,a:hover{outline-width:0}abbr[title]{border-bottom:none;text-decoration:underline;text-decoration:underline dotted}b,strong{font-weight:bolder}dfn{font-style:italic}h1{font-size:2em;margin:.67em 0}mark{background-color:#ff0;color:#000}small{font-size:80%}sub,sup{font-size:75%;line-height:0;position:relative}sub{bottom:-.25em}sup{top:-.5em}img{border-style:none}svg:not(:root){overflow:hidden}code,kbd,pre,samp{font-family:monospace,monospace;font-size:1em}figure{margin:1em 40px}hr{box-sizing:content-box;height:0}button,input,optgroup,select,textarea{font:inherit;margin:0}optgroup{font-weight:700}button,select{text-transform:none}[type=submit],[type=reset],button,html [type=button]{-webkit-appearance:button}[type=button]::-moz-focus-inner,[type=reset]::-moz-focus-inner,[type=submit]::-moz-focus-inner,button::-moz-focus-inner{border-style:none;padding:0}[type=button]:-moz-focusring,[type=reset]:-moz-focusring,[type=submit]:-moz-focusring,button:-moz-focusring{outline:ButtonText dotted 1px}fieldset{border:1px solid silver;margin:0 2px;padding:.35em .625em .75em}legend{box-sizing:border-box;color:inherit;display:table;max-width:100%;padding:0;white-space:normal}textarea{overflow:auto}[type=checkbox],[type=radio]{box-sizing:border-box;padding:0}[type=number]::-webkit-inner-spin-button,[type=number]::-webkit-outer-spin-button{height:auto}[type=search]{-webkit-appearance:textfield;outline-offset:-2px}[type=search]::-webkit-search-cancel-button,[type=search]::-webkit-search-decoration{-webkit-appearance:none}::-webkit-input-placeholder{color:inherit;opacity:.54}::-webkit-file-upload-button{-webkit-appearance:button;font:inherit}code{background:#ffffff}.highlight{background:#ffffff}.highlight pre{background-color:#fff;font-size:16px}.highlight .c{color:#999988;font-style:italic}.highlight .err{color:#a61717;background-color:#e3d2d2}.highlight .k{font-weight:bold}.highlight .o{font-weight:bold}.highlight .cm{color:#999988;font-style:italic}.highlight .cp{color:#999999;font-weight:bold}.highlight .c1{color:#999988;font-style:italic}.highlight .cs{color:#999999;font-weight:bold;font-style:italic}.highlight .gd{color:#000000;background-color:#fdd}.highlight .gd .x{color:#000000;background-color:#faa}.highlight .ge{font-style:italic}.highlight .gr{color:#a00}.highlight .gh{color:#999}.highlight .gi{color:#000000;background-color:#dfd}.highlight .gi .x{color:#000000;background-color:#afa}.highlight .go{color:#888}.highlight .gp{color:#555}.highlight .gs{font-weight:bold}.highlight .gu{color:#aaa}.highlight .gt{color:#a00}.highlight .kc{font-weight:bold}.highlight .kd{font-weight:bold}.highlight .kp{font-weight:bold}.highlight .kr{font-weight:bold}.highlight .kt{color:#445588;font-weight:bold}.highlight .m{color:#099}.highlight .s{color:#d14}.highlight .na{color:teal}.highlight .nb{color:#0086B3}.highlight .nc{color:#445588;font-weight:bold}.highlight .no{color:teal}.highlight .ni{color:purple}.highlight .ne{color:#990000;font-weight:bold}.highlight .nf{color:#990000;font-weight:bold}.highlight .nn{color:#555}.highlight .nt{color:navy}.highlight .nv{color:teal}.highlight .ow{font-weight:bold}.highlight .w{color:#bbb}.highlight .mf{color:#099}.highlight .mh{color:#099}.highlight .mi{color:#099}.highlight .mo{color:#099}.highlight .sb{color:#d14}.highlight .sc{color:#d14}.highlight .sd{color:#d14}.highlight .s2{color:#d14}.highlight .se{color:#d14}.highlight .sh{color:#d14}.highlight .si{color:#d14}.highlight .sx{color:#d14}.highlight .sr{color:#009926}.highlight .s1{color:#d14}.highlight .ss{color:#990073}.highlight .bp{color:#999}.highlight .vc{color:teal}.highlight .vg{color:teal}.highlight .vi{color:teal}.highlight .il{color:#099}.highlight .lineno{color:rgba(0,0,0,0.3);padding:0 10px;-webkit-user-select:none;-moz-user-select:none;-o-user-select:none}.lineno::-moz-selection{background-color:transparent}.lineno::selection{background-color:transparent}body{padding:32px;color:#333333;background-color:#ffffff;font-family:Fira Sans, serif}.container{max-width:45em;margin:0 auto;font-size:20px}body blockquote{border-left:2px solid #333333 !important}article{font-size:1em}h1,h2,h3{font-weight:800;font-family:Fira Sans, sans-serif}h1{text-align:center;font-size:2.0em}h2{text-align:center;font-size:1.2em;margin-top:4em}h3{text-align:center;font-size:1em}h4{text-align:center}a{text-decoration:underline;font-weight:normal}a,a:visited,a:hover,a:active{color:#0085a1}*{max-width:100%}pre,figure,.wp-caption{margin:0px -10px 20px -10px;padding:0px 10px 0px 10px}blockquote{margin:0;padding:0px 10px 0px 10px;border-radius:5px}p>img:only-child,p>a:only-child>img:only-child,.wp-caption img,figure img{display:block}img{margin-left:auto;margin-right:auto}.caption,.wp-caption-text,figcaption{font-size:0.9em;line-height:1.48em;font-style:italic}code,pre{white-space:pre;overflow:visible;font-family:Fira Code, monospace}ul,ol{padding:0}ul{padding-left:30px;list-style:disc}ol{padding-left:30px;list-style:decimal}.post-link{padding-bottom:10px;text-align:center}.post-link a{text-decoration:none;color:#333333}.post-link a:focus,.post-link a:hover{color:#0085a1}.post-link .post-title{margin:0;font-size:18px}nav{text-align:center}nav a{font-size:1.4em}nav a,nav a:visited{text-decoration:none;color:#333333}nav a:focus,nav a:hover{color:#0085a1}.menu ul{list-style:none;padding:0;margin:0}header{margin:2em 0 2em 0;text-align:center}header h1{margin:0}footer{margin-top:4em;text-align:center;font-style:italic}iframe{width:560px;height:315px;display:block;margin:0 auto;padding-top:1em}table{margin-left:auto;margin-right:auto;border-collapse:collapse}table,th,td{padding:0.5em;border:0.5px solid #333333}hr{width:7em;margin-top:3em;margin-bottom:3em;border:0;height:1px;background-image:linear-gradient(to right, transparent, rgba(0,0,0,0.75), transparent)}</style><nav> <a href="/"> JAMIE BRANDON </a></nav><div class="container"><header><h1>Notes on 'Designing with the Mind in Mind'</h1></header><article role="main"><p><a href="https://smile.amazon.com/dp/B00HLLN0PI/">https://smile.amazon.com/dp/B00HLLN0PI/</a><p>UI guidelines easier to understand if we understand the cognitive basic, especially in novel contexts.<p>Need explanatory model for:<ul><li>explanatory evaluation<li>generative design<li>codification of knowledge</ul><p>A/B testing without a model is like driving by bouncing off the guard rails.<h2 id="biased-perception">Biased perception</h2><ul><li>Perceptual priming<li>Familiar frames<ul><li>next/back buttons<li>UI needs to be consistent, because the user will see what they expect to see, not what is actually there</ul><li>Habituation<ul><li>eg dismissing warning messages without reading them</ul><li>Attentional blink<li>Top down bias (cf <a href="https://slatestarcodex.com/2017/09/06/predictive-processing-and-perceptual-control/">PP</a>)<ul><li>eg McGurk effect<li>eg ventriloquism<li>eg illusory flash</ul><li>Guided + filtered by goals<ul><li>Guides gaze and attention<li>Primes perception<li>eg cocktail party effect</ul><li>Avoid ambiguity<ul><li>Test that all users thave the same interpretation</ul><li>Stick to convention<li>Be internally consistent<li>Understand users goals and map UI elements to goals</ul><h2 id="structure">Structure</h2><ul><li>Vision automatically groups features into structure based on:<ul><li>Proximity<li>Similarity<li>Movement (common fate)<li><strong>Alignment</strong></ul><li>Also resolves ambiguity with bias for:<ul><li>Continuity - hidden forms (eg sliders)<li>Closure - whole objects (eg stacks)<li>Symmetry - low complexity scene (eg seeing complex 2d image as simple 3d scene)</ul><li>Figure/ground<ul><li>By features, but also by attention<li>eg watermark behind text</ul><li>Inspect UI for unintended relations</ul><h2 id="color">Color</h2><ul><li>Rods max out in typical env<li>3 kinds of cones - low/med/high freq (for most people, actually 2-4 in general)<li>High-freq cones much less sensitive than low/med-freq<li>Cone signals combined into subtraction channels<ul><li>Med - low = red/green<li>High - low = yellow/blue<li>Med + low = black/white</ul><li><p>Then do edge detection -ish - subtract neighboring signals<li>Optimized to detect contrast, not brightness<li>Less able to distinguish regions of colour which are:<ul><li>Pale<li>Small/thin<li>Far apart</ul><li>User won’t see same colors as you<ul><li>Color blindness = one or more cone kinds less sensitive<li>Different displays<li>Display angle<li>Ambient light/shadow</ul><li>Choose colors that contrast strongly on at least one channel<li>Use redundant cues - color, weight, size, placement, symbols, text<li>Test using color blindness simulators and grayscale<li>Don’t place opposing pairs (red-green, yellow-blue, black-white) next to each other - causes shimmer</ul><h2 id="search">Search</h2><ul><li>Users scan for structure &gt; reading for content<li>Avoid burying structure in noise<li>Create visual hierarchy with:<ul><li>Positioning (top/bottom)<li>Grouping<li>Size/weight</ul><li>Chunk info<ul><li>eg allow users to put spaces in phone and credit card numbers</ul></ul><h2 id="peripheral">Peripheral</h2><ul><li>Fovea is about 1% of visual field - thumbnail at arms length<li>Much higher ‘resolution’ in fovea<ul><li>Cone:rod is ~20:1 inside fovea vs ~1:20 outside<li>Signals from outside fovea are increasingly lossily compressed<li>~50% of visual cortex dedicated to signals from fovea</ul><li>Peripheral vision typically as bad as ~20/200 = legally blind<li>Peripheral guides gaze<ul><li>Detects motion<li>Perceives large patches of color<li>Sensitive to low light</ul><li>Message placement<ul><li>Put where the user is looking already<ul><li>eg pressing sign-in button and error appears at top of page - invisible in peripheral</ul><li>Use conventional error symbols<li>Reserve red for errors<li>Catch errors early while user is still looking at that input</ul><li>Popup, shake, beep will get attention but:<ul><li>Annoying<li>Can be mistaken for ad<li>Habituation<li>=&gt; Last resort for really urgent errors</ul><li>Search is linear, but can parallel scan for features that peripheral vision can see<ul><li>eg search for z vs search for bold letter</ul><li>Don’t move items - requires vision instead of muscle memory<ul><li>eg menu placement by most recent</ul><li>Try to make items primable<ul><li>eg searching for errors = searching for red or error symbol</ul></ul><h2 id="reading">Reading</h2><ul><li>Not innate<li>Requires detailed vision<ul><li>Width of fovea is ~6-8 chars<li>Can see ~30-40 chars blurrily<li>Biased in forward language direction eg Euro readers can see more chars to the right<li>Saccade several times /s, ~100ms duration</ul><li>Movement is mostly linear, guided by peripheral vision<ul><li>Usually land inside word<li>Can skip over small/predicatable words<li>Sometimes saccade backwards<li>At end of line, jump to guessed location of next line</ul><li>Both bottom-up and top-down processing<ul><li>Early theories suggested top-down dominates (eg speed-reading schools) but no longer believed<li>Top-down is more dominant in less-skilled readers than in more-skilled readers<li>Top-down is more dominant in poor conditions<li><strong>I’m interpreting this to say that in skilled readers the bottom-up signal is strong enough to overwhelm any top-down signal</strong></ul><li>Avoid ‘poor conditions’<ul><li>Uncommon or unfamiliar vocab<ul><li>Especially technical jargon</ul><li>Difficult fonts<ul><li>eg all-caps</ul><li>Small text<li>Noise background<ul><li>Think how hard captchas are to read</ul><li>Excessive repetition - makes it easy to lose track of position<li>Centered text - can’t easily jump to start of next line</ul></ul><h2 id="long-term-memory">Long-term memory</h2><ul><li>High-capacity, low-fidelity, error-prone<li>Experiences are highly compressed - not raw sensory data<li>Different kinds:<ul><li>episodic - past events<li>procedural - action sequences<li>semantic - facts and relationships</ul><li>Weighted by emotion<li><p>Retractively alterable<li>Password requirements - allow for memorable phrases, not meaningless strings<li>Security questions - let user pick their own<li>Consistency = less steps to remember<li>Discoverability - for actions the user has forgotten</ul><h2 id="working-memory">Working memory</h2><ul><li>Working memory not a ‘place’ - not RAM<li>(<strong>Not confident in my understanding of this section:</strong>)<ul><li>Each perceptual system has some internal representations which can be repeatedly refreshed (instead of processing current inputs)<li>Long-term memory patterns can be activated by percepts or recall and then repeatedly refreshed<li>Working memory consists of applying limited focus/attention to a small number of items<li>Everything outside of that focus is at risk of fading away</ul><li>3-5 items, but controversy over what exactly should be measured<ul><li>eg items with more features lower limit, so should we count features instead of items?</ul><li>Chunking<li>Items can be both pulled into working memory by conscious processes or pushed by automatic processes<li>Strong candidates for involuntary pushing:<ul><li>Motion (especially near or towards)<li>Threats<li>Faces<li>Sex and food<li>Goals / primed patterns</ul><li>Modes and mode error<ul><li>Avoid modes or provide very clear signals</ul><li>Keep task-relevant info on-screen in case it falls out of working memory<ul><li>eg search engines now show the search query above the results<li>Keep instructions open while user is following instructions</ul><li>Calls to action - max 1 per message<li>Navigation depth =&gt; breadcrumbs</ul><h2 id="goal-seeking">Goal-seeking</h2><ul><li>Goals decompose into nested subgoals - strains working memory<li>Having to spend limited attention/memory on tools may push out goal structure<ul><li>Familiar paths = low cognitive load, less risk of derailment<li>For non-frequent tasks prefer mindless funnel over mechanical efficiency<li>For frequent tasks still provide funnel but also hint towards more efficient routes</ul><li>Percept + memory is goal-filterd<ul><li>Inattentional blindness<ul><li>eg gorilla basketball</ul><li>Change blindness<ul><li>eg price change when changing options</ul></ul><li>‘Following information scent’ - scanning for next action<ul><li>Priming is pretty literal eg ‘buy’ or ‘ticket’ but not ‘bargain trips’</ul><li>External aids<ul><li>eg tab lists<li>eg checklists<li>Let users mark/group objects</ul><li>Goal-Execute-Evaluate loop<ul><li>nested, multi-level<li>goal - map entry paths to common goals<li>execute - map actions to tasks, not implementations<ul><li>ie not git</ul><li>eval - show progress / status</ul><li>Attention lost after goal, may miss cleanup tasks<ul><li>do automatically if possible<li>remind user<li>delay goal satisfaction until after cleanup<ul><li>eg atm</ul></ul></ul><h2 id="recognition-vs-recall">Recognition vs recall</h2><ul><li>Recognition<ul><li>Retrieval with perceptual support<li>Percepts causes neural pattern which is similar to matching memories. No need for search.<ul><li>(<strong>How is the similarity detected?</strong>)</ul><li>eg choosing command from list</ul><li>Recall<ul><li>Retrieval without perceptual support<li>eg typing commands from memory</ul><li>Better at recognizing images than text<ul><li>=&gt; icons</ul><li>Scale-invariant<ul><li>=&gt; thumbnails</ul><li>Use common themes for site so user can recognize when they arrive/leave</ul><h2 id="automatic-vs-controlled">Automatic vs controlled</h2><ul><li><p>Dual-system theory - S1/automatic, S2/controlled<li>Do S2 work for the user<ul><li>eg meeting planner shows times in all timezones, even though user could easily add the offset</ul><li>Replace calculation with perception<ul><li>eg goto line -&gt; scroll bar - easier to visually pick out halfway point than to count total lines and divide by 2<li>eg coordinates -&gt; alignment guides - easier to drag until aligned than to add grid increments to coords</ul></ul><h2 id="learning">Learning</h2><ul><li>Controlled -&gt; automatic<li>Learn faster when:<ul><li>Practice is:<ul><li>frequent<li>regular<li>precise (<strong>not clear what is meant by precise</strong>)</ul><li>Operation is:<ul><li>Task-focused<ul><li>Nouns/verbs in same domain as problem, not implementation<li>‘Gulf of execution’</ul><li>Simple<ul><li>Features interact, so complexity is super-linear</ul><li>Consistent<ul><li>Predicatable, compressible</ul></ul><li>Vocab is:<ul><li>Task-focused<ul><li>Relative to what user cares about, not implementation<li>eg local/remote -&gt; private/shared</ul><li>Familiar<ul><li>Guessible<li>Understood by S1</ul><li>Consistent<ul><li>Maps 1:1 to concepts</ul></ul></ul><li>Low-risk encourages exploration<ul><li>Make mistakes impossible<li>Clearly detect errors<li>Allow undo or correct</ul></ul><h2 id="bias">Bias</h2><ul><li>Decision support systems<li>Help avoid bias<ul><li>Provide all options - prevents limited framing<li>Propose variations on user solutions - aids creative search<li>Perform calculations, comparisons, inference etc automatically<li>Let users declare assumptions and then check them automatically</ul><li>Vizualization - map problem domain into existing S1 processes<ul><li>eg Chernoff faces (<strong>vaguely recall reading that these are much less effective than originally claimed</strong>)</ul><li>Persuasive systems - target S1 to influence users</ul><h2 id="hand-eye-coordination">Hand-eye coordination</h2><ul><li>Movement is open-loop ballistic followed by closed-loop correction<li>Fitts law - <script type="math/tex">T=O(\log(1+\frac{D}{W}))</script><ul><li>Edge of screen is effectively infinitely wide - can hit it with open-loop only</ul><li>Steering law - to stay within path <script type="math/tex">T = O(\frac{D}{W})</script><ul><li>eg pull-right menus<li>eg old-school scrollbars</ul><li>Make targets big enough<li>Make actual target &gt;= visible target<li>Accept clicks on labels<li>Leave space between targets<li>Put important targets near edge<li>Pull-down menus -&gt; pop-up menus - lower avg distance</ul><h2 id="time-scales">Time scales</h2><ul><li>Reponsiveness &gt; effectiveness for user satisfaction (many citations)<li>Responsive doesn’t necessarily mean fast.<ul><li>Ack input<li>Give estimated waits<li>Let user do other things whilst waiting<li>Run non-user tasks in background, without blocking UI<ul><li>eg GC<li>eg defrag</ul></ul><li>~5ms subliminal perception - visual priming, basic emotions<li>~100ms between visual event and full perception<ul><li>But brain does lag correction + post-hoc editing</ul><li>&lt;100ms limit of ‘perceptual locking’ between sound and visual event<ul><li>eg drummer closing from distance - perceived lag doesn’t go linearly to zero but instead jumps from 100ms to 0ms</ul><li>~100ms saccade<li>&lt;140ms limit of intuitive (<strong>physical?</strong>) causality<ul><li>eg typing with &gt;140ms lag makes user conscious of act of typing</ul><li>~50ms / item to subitize<li>~300ms / item to count<li>~200ms editorial window, within which events can be reordered or edited before conscious experience<ul><li>eg dot disappearing and appearing again will be perceived as having moved linearly if &lt;200ms</ul><li>~500ms attentional blink<li>~700ms visual-motor response<ul><li>but ~80ms for flinch (<strong>time to start of motion?</strong>)</ul><li>~6-30s unbroken attention to unit task before switch<ul><li>(<strong>think of this as scheduling quantum?</strong>)</ul><li>Rules of thumb:<ul><li>~10ms sound, digital ink (<strong>why is ink noticable but not other ui interactions? automaticity?</strong>)<li>~100ms ack, react, animate, hand-eye (eg drag+drop)<li>~1s finish or estimate duration, user reaction to new information<li>~10s unit task</ul><li>Use busy indicator for <em>anything</em> that blocks user input, even if normally &lt;100ms<li>Display important info first - rest can sneakily render while user is reacting<ul><li>eg progressive rendering for images<li>eg approx results for database queries</ul><li>Delays between unit tasks are less derailing than delays within unit tasks<ul><li>‘task closure’<li>eg delay on autosave =&gt; wait until typing stops</ul><li>For tasks requiring hand-eye coordination, fake it if you can’t make it<ul><li>eg scrolling just shows page boundaries, renders on pause<li>eg rubber-band resize</ul><li>Precompute high-prob tasks during low load<ul><li>eg render next few pages while user is reading current page</ul><li>Start progress indicators at 1% and don’t spend more than a few seconds at 100%<li>Prioritize tasks queues according to user priorities</ul></article><footer><div>Questions? Comments? Just want to chat?</div><div><a href="mailto:jamie@scattered-thoughts.net>jamie@scattered-thoughts.net">jamie@scattered-thoughts.net</a></div><br><p><a href="/feed.xml"><img src="/img/rss.png"></img></a></footer></div>
